from flask import Flask, render_template, request, jsonify
import os
import json
from datetime import datetime
import re
import subprocess
import sys
from pathlib import Path

# Import c√°c th∆∞ vi·ªán cho vector search
from langchain_community.embeddings import HuggingFaceEmbeddings
from langchain_community.vectorstores import FAISS
from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain_community.document_loaders import TextLoader
from langchain_google_genai import ChatGoogleGenerativeAI
from langchain.chains import RetrievalQA
from langchain.prompts import PromptTemplate
from dotenv import load_dotenv

app = Flask(__name__)

# T·∫£i c√°c bi·∫øn m√¥i tr∆∞·ªùng t·ª´ file .env
load_dotenv()

# ƒê·ªãnh nghƒ©a c√°c h·∫±ng s·ªë
DATA_PATH = "data.txt"
DB_FAISS_PATH = "faiss_index"
GOOGLE_API_KEY = os.getenv("GOOGLE_API_KEY")

def run_ingest_data():
    """Ch·∫°y file 1_ingest_data.py ƒë·ªÉ c·∫≠p nh·∫≠t vector database"""
    try:
        print("üîÑ ƒêang c·∫≠p nh·∫≠t vector database...")
        result = subprocess.run([sys.executable, "1_ingest_data.py"], 
                              capture_output=True, text=True, encoding='utf-8')
        if result.returncode == 0:
            print("‚úÖ C·∫≠p nh·∫≠t vector database th√†nh c√¥ng!")
            return True
        else:
            print(f"‚ùå L·ªói khi c·∫≠p nh·∫≠t vector database: {result.stderr}")
            return False
    except Exception as e:
        print(f"‚ùå L·ªói khi ch·∫°y ingest_data: {e}")
        return False

def check_and_update_database():
    """Ki·ªÉm tra v√† c·∫≠p nh·∫≠t database n·∫øu c·∫ßn"""
    data_file = Path(DATA_PATH)
    db_path = Path(DB_FAISS_PATH)
    
    # Ki·ªÉm tra xem c√≥ c·∫ßn c·∫≠p nh·∫≠t kh√¥ng
    if not db_path.exists() or not (db_path / "index.faiss").exists():
        print("üìä Vector database ch∆∞a t·ªìn t·∫°i, ƒëang t·∫°o m·ªõi...")
        return run_ingest_data()
    
    # Ki·ªÉm tra xem file data.txt c√≥ thay ƒë·ªïi kh√¥ng
    if data_file.exists():
        data_mtime = data_file.stat().st_mtime
        db_mtime = db_path.stat().st_mtime if db_path.exists() else 0
        
        if data_mtime > db_mtime:
            print("üìù Ph√°t hi·ªán thay ƒë·ªïi trong data.txt, ƒëang c·∫≠p nh·∫≠t database...")
            return run_ingest_data()
    
    return True

def load_vector_database():
    """Load vector database t·ª´ FAISS"""
    try:
        if not os.path.exists(DB_FAISS_PATH):
            print("‚ùå Vector database kh√¥ng t·ªìn t·∫°i!")
            return None
        
        embeddings = HuggingFaceEmbeddings(
            model_name='sentence-transformers/all-MiniLM-L6-v2',
            model_kwargs={'device': 'cpu'}
        )
        
        # Th√™m allow_dangerous_deserialization=True ƒë·ªÉ cho ph√©p load database
        db = FAISS.load_local(DB_FAISS_PATH, embeddings, allow_dangerous_deserialization=True)
        print("‚úÖ ƒê√£ load vector database th√†nh c√¥ng!")
        return db
    except Exception as e:
        print(f"‚ùå L·ªói khi load vector database: {e}")
        return None

def create_qa_chain(db):
    """T·∫°o QA chain v·ªõi Google Gemini LLM"""
    try:
        if not GOOGLE_API_KEY:
            print("‚ùå Kh√¥ng t√¨m th·∫•y GOOGLE_API_KEY trong file .env")
            return None
        
        # Kh·ªüi t·∫°o LLM c·ªßa Google
        llm = ChatGoogleGenerativeAI(
            model="gemini-1.5-flash", 
            temperature=0.2, 
            google_api_key=GOOGLE_API_KEY
        )
        
        # T·∫°o prompt template th√¥ng minh
        prompt_template = """B·∫°n l√† m·ªôt tr·ª£ l√Ω AI th√¥ng minh chuy√™n v·ªÅ ph√¢n t√≠ch v√† tr·∫£ l·ªùi c√¢u h·ªèi v·ªÅ t√†i li·ªáu.

H∆Ø·ªöNG D·∫™N X·ª¨ L√ù C√ÇU H·ªéI:

1. N·∫øu c√¢u h·ªèi y√™u c·∫ßu t√≥m t·∫Øt ch∆∞∆°ng/s√°ch: T√¨m t·∫•t c·∫£ th√¥ng tin li√™n quan v√† t√≥m t·∫Øt c√≥ c·∫•u tr√∫c
2. N·∫øu c√¢u h·ªèi v·ªÅ kh√°i ni·ªám/ƒë·ªãnh nghƒ©a: Gi·∫£i th√≠ch r√µ r√†ng v√† ƒë∆∞a ra v√≠ d·ª•
3. N·∫øu c√¢u h·ªèi so s√°nh/ƒë·ªëi chi·∫øu: Ph√¢n t√≠ch ƒëi·ªÉm gi·ªëng v√† kh√°c nhau
4. N·∫øu c√¢u h·ªèi v·ªÅ √Ω ki·∫øn/quan ƒëi·ªÉm: Tr√¨nh b√†y c√°c quan ƒëi·ªÉm kh√°c nhau t·ª´ t√†i li·ªáu
5. N·∫øu c√¢u h·ªèi th·ª±c h√†nh/·ª©ng d·ª•ng: ƒê∆∞a ra h∆∞·ªõng d·∫´n c·ª• th·ªÉ
6. N·∫øu c√¢u h·ªèi kh√¥ng t√¨m th·∫•y th√¥ng tin: N√≥i r√µ v√† ƒë·ªÅ xu·∫•t t√¨m ki·∫øm kh√°c

Y√äU C·∫¶U TR·∫¢ L·ªúI:
- Tr·∫£ l·ªùi ƒë·∫ßy ƒë·ªß, ch√≠nh x√°c v√† c√≥ c·∫•u tr√∫c
- S·ª≠ d·ª•ng th√¥ng tin t·ª´ t√†i li·ªáu ƒë∆∞·ª£c cung c·∫•p
- N·∫øu th√¥ng tin kh√¥ng ƒë·ªß, h√£y n√≥i r√µ
- Tr·∫£ l·ªùi b·∫±ng ti·∫øng Vi·ªát (tr·ª´ khi ƒë∆∞·ª£c y√™u c·∫ßu kh√°c)

Context: {context}
Question: {question}

Answer:"""

        PROMPT = PromptTemplate(
            template=prompt_template,
            input_variables=["context", "question"]
        )
        
        # T·∫°o QA chain
        qa_chain = RetrievalQA.from_chain_type(
            llm=llm,
            chain_type="stuff",
            retriever=db.as_retriever(search_kwargs={'k': 10}),
            return_source_documents=True,
            chain_type_kwargs={"prompt": PROMPT}
        )
        
        return qa_chain
    except Exception as e:
        print(f"‚ùå L·ªói khi t·∫°o QA chain: {e}")
        return None

def generate_answer_with_llm(query, qa_chain):
    """T·∫°o c√¢u tr·∫£ l·ªùi s·ª≠ d·ª•ng LLM"""
    if not qa_chain:
        return "Xin l·ªói, kh√¥ng th·ªÉ kh·ªüi t·∫°o AI model. Vui l√≤ng ki·ªÉm tra API key v√† th·ª≠ l·∫°i."
    
    try:
        # S·ª≠ d·ª•ng QA chain ƒë·ªÉ t·∫°o c√¢u tr·∫£ l·ªùi
        result = qa_chain.invoke({"query": query})
        
        # L·∫•y c√¢u tr·∫£ l·ªùi t·ª´ LLM
        answer = result["result"]
        
        # Th√™m th√¥ng tin v·ªÅ s·ªë ƒëo·∫°n vƒÉn b·∫£n ƒë√£ s·ª≠ d·ª•ng
        if result.get('source_documents'):
            num_docs = len(result['source_documents'])
            total_chars = sum(len(doc.page_content) for doc in result['source_documents'])
            answer += f"\n\n---\n*S·ª≠ d·ª•ng {num_docs} ƒëo·∫°n vƒÉn b·∫£n ({total_chars} k√Ω t·ª±)*"
        
        return answer
    except Exception as e:
        print(f"‚ùå L·ªói khi t·∫°o c√¢u tr·∫£ l·ªùi: {e}")
        return f"Xin l·ªói, c√≥ l·ªói x·∫£y ra khi x·ª≠ l√Ω c√¢u h·ªèi: {str(e)}"

@app.route('/')
def index():
    return render_template('index.html')

@app.route('/search', methods=['POST'])
def search():
    try:
        data = request.get_json()
        query = data.get('query', '').strip()
        
        if not query:
            return jsonify({'error': 'Vui l√≤ng nh·∫≠p c√¢u h·ªèi'})
        
        # Load vector database
        db = load_vector_database()
        if not db:
            return jsonify({'error': 'Kh√¥ng th·ªÉ load vector database. Vui l√≤ng ki·ªÉm tra l·∫°i.'})
        
        # T·∫°o QA chain v·ªõi LLM
        qa_chain = create_qa_chain(db)
        if not qa_chain:
            return jsonify({'error': 'Kh√¥ng th·ªÉ kh·ªüi t·∫°o AI model. Vui l√≤ng ki·ªÉm tra API key.'})
        
        # T·∫°o c√¢u tr·∫£ l·ªùi s·ª≠ d·ª•ng LLM
        answer = generate_answer_with_llm(query, qa_chain)
        
        return jsonify({
            'success': True,
            'answer': answer,
            'timestamp': datetime.now().strftime('%H:%M:%S')
        })
        
    except Exception as e:
        return jsonify({'error': f'L·ªói: {str(e)}'})

@app.route('/api/suggestions')
def get_suggestions():
    """API l·∫•y danh s√°ch c√¢u h·ªèi g·ª£i √Ω"""
    suggestions = [
        "T√°c gi·∫£ Minh Ni·ªám l√† ai?",
        "N·ªôi dung s√°ch Hi·ªÉu V·ªÅ Tr√°i Tim",
        "L√†m th·∫ø n√†o ƒë·ªÉ s·ªëng h·∫°nh ph√∫c?",
        "C√°ch ch·ªØa l√†nh t·ªïn th∆∞∆°ng t√¢m h·ªìn",
        "Ngh·ªá thu·∫≠t s·ªëng h·∫°nh ph√∫c",
        "T√¨nh y√™u v√† h·∫°nh ph√∫c",
        "Chuy·ªÉn h√≥a phi·ªÅn n√£o",
        "Hi·ªÉu v·ªÅ c·∫£m x√∫c",
        "S·ªëng trong th∆∞∆°ng y√™u",
        "Kh√°m ph√° n·ªôi t√¢m",
        "C√°ch ƒë·ªëi m·∫∑t v·ªõi kh√≥ khƒÉn",
        "T√¨m ki·∫øm h·∫°nh ph√∫c ch√¢n th·∫≠t",
        "Ph√°t tri·ªÉn t√¢m linh",
        "C√°ch y√™u th∆∞∆°ng b·∫£n th√¢n",
        "X√¢y d·ª±ng m·ªëi quan h·ªá t·ªët ƒë·∫πp"
    ]
    return jsonify({'suggestions': suggestions})

@app.route('/api/status')
def get_status():
    """API ki·ªÉm tra tr·∫°ng th√°i h·ªá th·ªëng"""
    try:
        data_exists = os.path.exists(DATA_PATH)
        db_exists = os.path.exists(DB_FAISS_PATH)
        
        status = {
            'data_file_exists': data_exists,
            'vector_db_exists': db_exists,
            'system_ready': data_exists and db_exists,
            'timestamp': datetime.now().strftime('%Y-%m-%d %H:%M:%S')
        }
        
        if data_exists:
            data_size = os.path.getsize(DATA_PATH)
            status['data_size_mb'] = round(data_size / (1024 * 1024), 2)
        
        return jsonify(status)
    except Exception as e:
        return jsonify({'error': str(e)})

@app.route('/api/update-database', methods=['POST'])
def update_database():
    """API c·∫≠p nh·∫≠t vector database"""
    try:
        success = run_ingest_data()
        if success:
            return jsonify({
                'success': True,
                'message': 'C·∫≠p nh·∫≠t vector database th√†nh c√¥ng!'
            })
        else:
            return jsonify({
                'success': False,
                'message': 'C√≥ l·ªói x·∫£y ra khi c·∫≠p nh·∫≠t database.'
            })
    except Exception as e:
        return jsonify({
            'success': False,
            'message': f'L·ªói: {str(e)}'
        })

if __name__ == '__main__':
    print("üöÄ Kh·ªüi ƒë·ªông h·ªá th·ªëng h·ªèi ƒë√°p...")
    
    # Ki·ªÉm tra v√† c·∫≠p nh·∫≠t database khi kh·ªüi ƒë·ªông
    if check_and_update_database():
        print("‚úÖ H·ªá th·ªëng s·∫µn s√†ng!")
    else:
        print("‚ö†Ô∏è C√≥ l·ªói khi kh·ªüi t·∫°o database, nh∆∞ng ·ª©ng d·ª•ng v·∫´n c√≥ th·ªÉ ch·∫°y.")
    
    print("üåê Kh·ªüi ƒë·ªông web server...")
    app.run(debug=True, host='0.0.0.0', port=5000) 